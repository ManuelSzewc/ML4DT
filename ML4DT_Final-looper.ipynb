{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import max_norm\n",
    "from keras.constraints import MinMaxNorm\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions\n",
    "\n",
    "## these correspond to functions $\\cal{H}_1$ and $\\cal{H}_2$ as described in Appendix A of (insert arxiv id)\n",
    "## hh $\\equiv \\psi$ \n",
    "## aas $\\equiv \\alpha$ parameters\n",
    "## d0p $\\equiv \\tilde{\\alpha}$ parameters\n",
    "## d1p $\\equiv \\beta$ parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1(): # a function to sample random numbers in [0,1]\n",
    "    return random.random()\n",
    "\n",
    "rseed=1500135045936 # with this seed the health function 1 has a good behaviour\n",
    "random.seed(rseed)\n",
    "\n",
    "hh = 1.2 # Health handle (parameter $\\psi$ in article)\n",
    "aas = list(map(lambda x: 10*random.random(),range(5)))\n",
    "def P(x):\n",
    "    a0 = sum(aas)/2\n",
    "    return (np.abs((1/a0)*(a0 - sum([aas[k]*x[k] for k in range(5)]))))**(1/hh)\n",
    "random.seed(rseed)\n",
    "\n",
    "# hyperparameters d0 : 13 \n",
    "d0p=list(map(lambda x: 2*random.random()-1,range(13)))\n",
    "\n",
    "def d0(x):\n",
    "    return np.exp(-np.abs(d0p[0]*x[13]+d0p[1]*x[5]+d0p[2]*x[6]+d0p[3]*x[7]+d0p[4]*x[8]) + np.abs(d0p[5]*x[9]+d0p[6]*x[6]+d0p[7]*x[10]+d0p[8]*x[11])+ np.abs(d0p[9]*x[12]+d0p[10]*x[13]+d0p[11]*x[5]+d0p[12]*x[14])/10)\n",
    "\n",
    "# hyperparameters d1: 6 hyperparameters, numbers between -1 and 1.\n",
    "random.seed(rseed)\n",
    "d1p=list(map(lambda x: 2*random.random()-1,range(6)))\n",
    "\n",
    "def d1(x):\n",
    "    return 1 + 0.1*np.sin((d1p[0]*x[5]-np.abs(d1p[1]*x[8]+d1p[2]*x[9]+d1p[3]*x[10]))*(d1p[4]*x[0]*x[7]-d1p[5]*x[2]*x[14]))\n",
    "\n",
    "\n",
    "def sv(ss): # define the gaussian centered at 1, with spread ss \n",
    "    return np.abs(np.random.normal(1, ss))\n",
    "\n",
    "# to normalize, we first find the max value \n",
    "random.seed(rseed)\n",
    "fvalues=[]\n",
    "for k in range(500000):\n",
    "    randpoint = list(map(lambda x: p1(),range(15)));\n",
    "    fval = P(randpoint)*d0(randpoint)*d1(randpoint)\n",
    "    fvalues.append(fval)\n",
    "max0 = max(fvalues)\n",
    "psh = np.poly1d([2*max0, max0])\n",
    "\n",
    "# \n",
    "def totalfuncsh1(x,sh):    \n",
    "    ff = P(x)*d0(x)*d1(x)*sv(sh);\n",
    "    maxtot=psh(sh)\n",
    "    if ff >= maxtot:\n",
    "        return 1\n",
    "    else:\n",
    "        return ff/maxtot\n",
    "    \n",
    "    \n",
    "# Function H_2\n",
    "\n",
    "def fsh(x,y,sh):\n",
    "    tmp = (1/15)*sv(sh)*abs(x[0]+(y[0]+3*y[1]-y[2])*(x[4]-x[2])+np.sinh(y[6]-y[5])-5*np.exp(-(y[8]-y[3])));\n",
    "    if tmp > 1: tmp = 1;\n",
    "    if tmp < 0: tmp = 0\n",
    "    return tmp\n",
    "\n",
    "def totalfuncsh2(x,sh):\n",
    "    return fsh(x[:5],x[5:],sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other definitions\n",
    "\n",
    "### rdtbest : samples ntrials drugs at random, then administers each to npatients/2, leaving the other npatients/2 with a placebo sample. Compares the average value of <H(x,y_trial)>  with those taking placebo <H(x,0)>. Function returns the list of drugs in their performing order, along with the list of (x,y) then used to train NN@RDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntrials = how many trials \n",
    "# npatients = how many patients in each trial\n",
    "# placebosize = 0.5 default value\n",
    "def rdtbest(ntrials,npatients,placebosize=0.5): \n",
    "    drugs = [list(map(lambda x: p1(),range(10))) for k in range(ntrials)]\n",
    "    trialdata=[]\n",
    "    for dr in drugs:\n",
    "        drpoints = []\n",
    "        for p in range(npatients):\n",
    "            if(p <= int(placebosize*npatients)):\n",
    "                drpoints.append(list(map(lambda x: p1(),range(5))) + [0]*10)\n",
    "            if(p > int(placebosize*npatients)):\n",
    "                drpoints.append(list(map(lambda x: p1(),range(5))) + dr)\n",
    "        trialdata.append(drpoints)    \n",
    "    trialflat = []\n",
    "    for tr in trialdata:\n",
    "        trialflat += tr \n",
    "    fs = [list(map(lambda x: totalfuncsh(x,sh),tr)) for tr in trialdata]        \n",
    "    favgsminus = []\n",
    "    for f in fs:\n",
    "        favgsminus.append(np.mean(f[int(placebosize*npatients):])-np.mean(f[:int(placebosize*npatients)]))\n",
    "    favgsminus,drugs  = (list(t) for t in zip(*sorted(zip(favgsminus,drugs),reverse=True)))\n",
    "    return drugs, trialflat \n",
    "#returns the drugs in the order that maximize <H(x,yn)> - <H(x,0)>.\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "#Creates a fully connected NN with input dimension 15 and output dimension 1, from a list of integers ll\n",
    "# Each of this integers corresponds to the number of neurons per hidden layer.\n",
    "# ll = [10,2] corresponds to a NN with 4 layers, the input layer of 15, then two hidden layers of 10 and 2 neurons\n",
    "# each, and finally the output neuron\n",
    "\n",
    "# We use RELU activation for all layers.\n",
    "# All hidden layers but the first one, and the output layer have biases set to zero\n",
    "# This is done to prevent the NN from having a minimum different from zero\n",
    "\n",
    "# We allow for dropout \"drop\" and learning rate \"lr\" parameters\n",
    "\n",
    "def makemodel(ll,drop,lr):\n",
    "    mm = Sequential()\n",
    "    mm.add(Dense(input_dim=15, activation=\"relu\", units=ll[0], kernel_initializer=\"normal\"))\n",
    "    mm.add(Dropout(drop))\n",
    "    for l in ll[1:]:\n",
    "        mm.add(Dense(activation=\"relu\", units=l, kernel_initializer=\"normal\",use_bias=False))\n",
    "        mm.add(Dropout(drop))\n",
    "    mm.add(Dense(activation=\"relu\", units=1, kernel_initializer=\"normal\",use_bias=False))\n",
    "    mm.compile(optimizer=RMSprop(lr), loss='mse', metrics=['mae'])\n",
    "    return mm\n",
    "\n",
    "# This function trains the NN for regression.\n",
    "# After fitting, it evaluates the NN in 20k points, to find the maximum values predicted by the NN\n",
    "# Then, for each y in the top 1000 points that maximize the NN function, we evaluate the average value\n",
    "# of the NN with fixed y, over a list of patients. We then use this average to sort the top-performing drugs\n",
    "# and the function outputs the top 10. \n",
    "\n",
    "def NNmaximizer(trainset,model,epochs=1000,batch_size=None,val_split=0.2):\n",
    "    if batch_size == None:\n",
    "        batch_size = int(len(trainset)/25)\n",
    "    yvalues = list(map(lambda x: totalfuncsh(x,sh),trainset))\n",
    "    xvalues = np.array(trainset)\n",
    "    mod = model\n",
    "    history = mod.fit(xvalues, yvalues, validation_split=val_split, epochs=epochs, batch_size=batch_size, verbose=0); \n",
    "    testpo=[list(map(lambda x:p1(),range(15))) for k in range(20000)]\n",
    "    nntestvals = mod.predict(np.array(testpo));\n",
    "    l1, l2 = (list(t) for t in zip(*sorted(zip(nntestvals.tolist(),list(range(len(testpo)))),reverse=True)))\n",
    "    #select top 1000 drugs, scan fs over them\n",
    "    bestdrugs=[testpo[k][5:] for k in l2[:1000]]\n",
    "    fsalldrg=[]\n",
    "    for drg in bestdrugs:\n",
    "        drgpat = [listpats[k] + drg for k in range(len(listpats))]\n",
    "        fsdrg= mod.predict(np.array(drgpat));\n",
    "        fsalldrg.append(np.mean(fsdrg))\n",
    "    fsalldrg, bestdrugs = (list(t) for t in zip(*sorted(zip(fsalldrg,bestdrugs),reverse=True)))\n",
    "    return mod, bestdrugs[:10],history\n",
    "\n",
    "\n",
    "# These functions are for the tests of NN performance. They include Pearson R, Spearman R, Mean Squared Error, \n",
    "# and the AUC as a function of the threshold described in appendix B. \n",
    "\n",
    "def rspearman(sample, f, mod):\n",
    "    truth_f = np.array(list(map(lambda x:f(x,sh),sample)))\n",
    "    nn_f = np.array(mod.predict(np.array(sample))).T[0]\n",
    "    return spearmanr(truth_f,nn_f)\n",
    "\n",
    "def rpearson(sample, f, mod):\n",
    "    truth_f = np.array(list(map(lambda x:f(x,sh),sample)))\n",
    "    nn_f = np.array(mod.predict(np.array(sample))).T[0]\n",
    "    return pearsonr(np.array(truth_f),np.array(nn_f))\n",
    "\n",
    "def mse_test(sample, f, mod):\n",
    "    truth_f = np.array(list(map(lambda x:f(x,sh),sample)))\n",
    "    nn_f = np.array(mod.predict(np.array(sample))).T[0]\n",
    "    return truth_f, nn_f, mean_squared_error(np.array(truth_f),np.array(nn_f))\n",
    "\n",
    "def rocking_plot(sample, f, mod, threshold):\n",
    "    truth_f = np.array(list(map(lambda x:f(x,sh),sample)))\n",
    "    nn_f = np.array(mod.predict(np.array(sample))).T[0]\n",
    "    truth_f_thr=np.where(truth_f > threshold, 1, 0)\n",
    "    if(sum(truth_f_thr)==len(truth_f) or sum(truth_f_thr)==0.0):\n",
    "        return [1.0,1.0,1.0], 1.0\n",
    "    else:\n",
    "        return roc_curve(truth_f_thr,nn_f), roc_auc_score(truth_f_thr,nn_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for the run\n",
    "\n",
    "## placebofrac : controls the fraction of placebo, to be used in RDT trials\n",
    "## batchsize : controls how many patients per RDT trial.\n",
    "\n",
    "## ntrials list: a list of ntrial numbers. Each ntrial defines an RDT trial with ntrial * batchsize total patients, testing over ntrial random drugs\n",
    "\n",
    "## stochastics: a list of stochastic parameters, for each of the runs.\n",
    "\n",
    "## models_list: a list of all the NN models to be tested.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "placebofrac = 0.5\n",
    "batchsize = 100\n",
    "random.seed(rseed)\n",
    "listpats = [list(map(lambda x: p1(),range(5))) for k in range(10000)]\n",
    "\n",
    "\n",
    "stochastics = [0.0,0.05,0.2,0.4]\n",
    "ntrials_list = [5,10,20]\n",
    "\n",
    "models_list=[[100, 32, 10, 10, 10, 10, 10, 10]]\n",
    "\n",
    "\n",
    "## NN parameters\n",
    "lr = 0.001 #learning rate\n",
    "dropout= 0.1 # dropout\n",
    "nepochs=1000 #number of epochs \n",
    "\n",
    "bins=np.linspace(0,1,15) # bins for the plotting of the Health distributions densities\n",
    "\n",
    "\n",
    "## Selecting the health function between H1 and H2 \n",
    "case = 1\n",
    "\n",
    "if case == 1:\n",
    "    totalfuncsh = totalfuncsh1\n",
    "elif case == 2:\n",
    "    totalfuncsh = totalfuncsh2\n",
    "    \n",
    "    \n",
    "## A plot showing the expected distributions with and without drugs\n",
    "\n",
    "placebox=[list(map(lambda x: p1(),range(5)))+[0]*10 for k in range(10000)]\n",
    "drugx=[list(map(lambda x: p1(),range(15)))for k in range(10000)]\n",
    "#bins=np.linspace(0,1,14)\n",
    "fpl=list(map(lambda x:totalfuncsh(x,0.2),placebox))\n",
    "fdr=list(map(lambda x:totalfuncsh(x,0.2),drugx))\n",
    "plt.hist(fpl,histtype='step',density=True,bins=np.linspace(0,1,14),label='Placebo');\n",
    "plt.hist(fdr,histtype='step',density=True,bins=np.linspace(0,1,14),label='With drugs');\n",
    "plt.xlabel('Health');\n",
    "plt.ylabel('Distribution');\n",
    "plt.xlim([0,1.01]);\n",
    "plt.legend(loc='upper right',framealpha=0.1);\n",
    "plt.savefig('healthshape.png');\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop running:\n",
    "\n",
    "## running the following cell creates a folder \"foldername\"\n",
    "## Inside it creates a log.txt file where it stores all data from each of the runs\n",
    "## For each trial in ntrials, for each model in nmodels_list and for each noise value in stochastics, it generates the 4 types of plots present in the article\n",
    "\n",
    "### * a plot of the Health distributions for each of the methods: (no drug, RDT, NN@RDT, NNDT) \n",
    "### * a plot of the Loss functions for both NN and NN@RDT, as a function of epochs, for train and validation sets.\n",
    "### * a plot of NNoutput vs true Health, along with R and MSE values\n",
    "### * a plot of AUC of tagging with NN as function of the threshold in true health function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "foldername = \"folder\"\n",
    "if(os.path.exists(foldername) == False):\n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "f=open(foldername+\"/log.txt\",\"a+\")\n",
    "f.write('Meta Parameters: \\n')\n",
    "f.write('f: case '+ str(case) + '\\n')\n",
    "f.write('dropout =' + str(dropout)+'\\n')\n",
    "f.write('learning rate = ' + str(lr) + '\\n')\n",
    "f.write('random seed: '+str(rseed)+'\\n')\n",
    "f.write('models are:'+str(models_list)+'\\n');\n",
    "f.write('\\n');\n",
    "f.close();\n",
    "\n",
    "for ntrials in ntrials_list:\n",
    "    for nmodlist,modlist in enumerate(models_list):\n",
    "        nntrainset=[list(map(lambda x:p1(),range(15))) for k in range(ntrials*batchsize)]\n",
    "        nntestset=[list(map(lambda x:p1(),range(15))) for k in range(int(ntrials*batchsize*0.5))];\n",
    "        loopdrugs = []\n",
    "        listsall = []\n",
    "        meanvals = []\n",
    "        for sh in stochastics:\n",
    "            model = makemodel(modlist,drop=dropout,lr=lr)\n",
    "            model2 = makemodel(modlist,drop=dropout,lr=lr)\n",
    "            rdtdrugs, trialflat = rdtbest(ntrials,batchsize,placebosize=placebofrac)\n",
    "            listbrdt= list(map(lambda x:totalfuncsh(x,sh),[listpats[k] + rdtdrugs[0] for k in range(len(listpats))]))\n",
    "            listwrdt=list(map(lambda x:totalfuncsh(x,sh),[listpats[k]+ rdtdrugs[-1] for k in range(len(listpats))]))\n",
    "            listwod=list(map(lambda x:totalfuncsh(x,sh),[listpats[k]+ [0]*10 for k in range(len(listpats))]))\n",
    "\n",
    "            modeldrugsNN_fitted, modeldrugsNN,histNN=NNmaximizer(nntrainset,model,epochs=1000)\n",
    "            modeldrugsNN_fitted_same, modeldrugsNN_same,histNN_same=NNmaximizer(trialflat,model2,epochs=1000)\n",
    "\n",
    "            hists = [histNN,histNN_same]\n",
    "\n",
    "            top10NNdt = [list(map(lambda x:totalfuncsh(x,sh),[listpats[k] + modeldrugsNN[u] for k in range(len(listpats))])) for u in range(10)]\n",
    "            top10NNdt_same = [list(map(lambda x:totalfuncsh(x,sh),[listpats[k] + modeldrugsNN_same[u] for k in range(len(listpats))])) for u in range(10)]\n",
    "            top10NNmeanf=list(map(lambda x:np.mean(x),top10NNdt))\n",
    "            top10NNmeanf_same=list(map(lambda x:np.mean(x),top10NNdt_same))\n",
    "\n",
    "            listNNDT = top10NNdt[0]\n",
    "            listNNDT_same = top10NNdt_same[0]\n",
    "\n",
    "            loopdrugs.append([rdtdrugs,modeldrugsNN,modeldrugsNN_same])\n",
    "            listsall.append([listbrdt,listwrdt,listwod,listNNDT,listNNDT_same])\n",
    "            meanvals.append(list(map(lambda x: np.mean(x),[listbrdt,listwrdt,listwod,listNNDT,listNNDT_same])))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # plots:  \n",
    "            \n",
    "            \n",
    "            plt.hist(listNNDT,label='Best NNDT',alpha=1,histtype='step',density=True,bins=bins);\n",
    "            plt.hist(listNNDT_same,label='Best NN@RDT',alpha=1,histtype='step',density=True,bins=bins);\n",
    "            plt.hist(listbrdt,label='Best RDT',alpha=1,histtype='step',density=True,bins=bins);\n",
    "#            plt.hist(listwrdt,label='Worst RDT',alpha=1,histtype='step',density=True,bins=bins);\n",
    "            plt.hist(listwod,label='No drugs',alpha=1,histtype='step',density=True,bins=bins,color='C4');\n",
    "            plt.xlabel('Health');\n",
    "            plt.ylabel('Distribution');\n",
    "            plt.xlim([0,1.01]);\n",
    "            #plt.ylim([0,1.01]);\n",
    "            plt.legend(loc='upper right',framealpha=0.1);\n",
    "            plt.title('Stochastic: '+str(int(100*sh))+'%');\n",
    "            plt.savefig(foldername+\"/f_distr_\"+str(ntrials)+\"_\"+str(nmodlist)+\"_\"+str(sh)+\".png\");\n",
    "            plt.close();\n",
    "            x_mse,y_mse,val_mse = mse_test(nntestset,totalfuncsh,modeldrugsNN_fitted);\n",
    "            plt.scatter(x_mse,y_mse,label='NN output',color='red');\n",
    "            plt.plot(x_mse,x_mse,label='y = x', color='blue');\n",
    "            aux_max=max(np.max(x_mse),np.max(y_mse))*1.025\n",
    "            aux_min=min(np.min(x_mse),np.min(y_mse))*0.975\n",
    "            plt.xlim([np.min(x_mse)*(0.975),np.max(x_mse)*1.025]);\n",
    "            plt.ylim([aux_min,aux_max]);\n",
    "            plt.xlabel('$\\mathcal{H}$');\n",
    "            plt.ylabel('$\\mathcal{H}_{NN}$');\n",
    "            plt.legend(loc='lower right',framealpha=0.1);\n",
    "            rspear=round(rspearman(nntestset,totalfuncsh,modeldrugsNN_fitted)[0],4)\n",
    "            plt.text(aux_min+0.2*(aux_max-aux_min), aux_min+0.65*(aux_max-aux_min), 'MSE ='+str(round(val_mse,4)), horizontalalignment='center', verticalalignment='center',fontsize=12);\n",
    "            plt.text(aux_min+0.2*(aux_max-aux_min), aux_min+0.55*(aux_max-aux_min), 'Spearman R ='+str(rspear), horizontalalignment='center', verticalalignment='center',fontsize=12);\n",
    "            plt.savefig(foldername+\"/mse_\"+str(ntrials)+\"_\"+str(nmodlist)+\"_\"+str(sh)+\".png\");\n",
    "            plt.close();\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            fig,ax=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "            ax[0].plot(hists[0].history['loss'], label='loss')\n",
    "            ax[0].plot(hists[0].history['val_loss'], label='val_loss')\n",
    "            ax[0].legend(loc=\"upper right\",framealpha=0.1)\n",
    "            ax[0].set_xlabel('Epoch')\n",
    "            ax[0].set_ylabel('Loss')\n",
    "            ax[0].set_xlim([0.,1000.])\n",
    "            ax[0].set_title('NN with '+str(ntrials*batchsize)+' points')\n",
    "            ax[1].plot(hists[1].history['loss'], label='loss')\n",
    "            ax[1].plot(hists[1].history['val_loss'], label='val_loss')\n",
    "            ax[1].legend(loc=\"upper right\",framealpha=0.1)\n",
    "            ax[1].set_xlabel('Epoch')\n",
    "            ax[1].set_ylabel('Loss')\n",
    "            ax[1].set_xlim([0.,1000.])\n",
    "            ax[1].set_title('NN with '+str(ntrials*batchsize)+' points from RDT')\n",
    "            plt.savefig(foldername+\"/loss_\"+str(ntrials)+\"_\"+str(nmodlist)+\"_\"+str(sh)+\".png\");\n",
    "            plt.close();\n",
    "            \n",
    "            evaluated_f=np.array(list(map(lambda x:totalfuncsh(x,sh),nntestset)));\n",
    "            thresholds=np.linspace(np.min(evaluated_f)*1.01,np.max(evaluated_f),100);\n",
    "            aucs=list(map(lambda x:rocking_plot(nntestset,totalfuncsh,modeldrugsNN_fitted,x)[1],thresholds));\n",
    "            plt.plot(thresholds,aucs);\n",
    "            plt.xlabel(\"$w_t$\");\n",
    "            plt.ylabel(\"AUC\");\n",
    "            plt.xlim([np.min(evaluated_f)*1.01,1.01*np.max(evaluated_f)]);\n",
    "            plt.ylim([0.49,1.01]);\n",
    "            plt.savefig(foldername+\"/auc_scan_\"+str(ntrials)+\"_\"+str(nmodlist)+\"_\"+str(sh)+\".png\");\n",
    "            plt.close();\n",
    "\n",
    "\n",
    "            # PICKLING: \n",
    "      \n",
    "            #pickle.dump( [[[listNNDT,listNNDT_same,listbrdt,listwrdt,listwod],bins],[x_mse,y_mse,val_mse,rspear],hists,[thresholds,aucs]], open(foldername+\"/plots_\"+str(ntrials)+\"_\"+str(nmodlist)+\"_\"+str(sh)+\".pickle\", \"wb\" ) ) # for saving\n",
    "\n",
    "            # logging :\n",
    "            \n",
    "            f=open(foldername+\"/log.txt\",\"a+\")\n",
    "            f.write('\\n');\n",
    "            f.write('--------------------------------- \\n')\n",
    "            f.write(str(datetime.datetime.now())+'\\n \\n');\n",
    "            f.write('[ntrials,modlist,sh]: \\n')\n",
    "            f.write('['+str(ntrials)+','+str(modlist)+','+str(sh)+']')\n",
    "            f.write('\\n')\n",
    "            f.write('model params: '+str(model.count_params()))\n",
    "            f.write('\\n')\n",
    "            f.write('best NN mean: ' + str(np.mean(listNNDT))+'\\n')\n",
    "            f.write('best NN (RDT train data) mean: ' + str(np.mean(listNNDT_same))+'\\n')\n",
    "            f.write('best RDT mean: ' + str(np.mean(listbrdt))+'\\n')\n",
    "            f.write('worst RDT mean: ' + str(np.mean(listwrdt))+'\\n')\n",
    "            f.write('no drug mean: ' + str(np.mean(listwod))+'\\n')\n",
    "            f.write('MSE: ' + str(val_mse)+'\\n')\n",
    "            f.write('R Spearman: ' + str(rspearman(nntestset,totalfuncsh,modeldrugsNN_fitted))+'\\n')\n",
    "            f.write('R Pearson: ' + str(rpearson(nntestset,totalfuncsh,modeldrugsNN_fitted))+'\\n')\n",
    "            f.close()\n",
    " \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "f=open(foldername+\"/log.txt\",\"a+\");\n",
    "f.write('\\n');\n",
    "f.write('The End')\n",
    "f.close();\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
